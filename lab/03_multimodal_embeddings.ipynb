{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 03 — Multi-Modal Embeddings\n\n`voyage-multimodal-3.5` embeds **text and images into the same vector space**, enabling:\n- Text query → find matching images\n- Image query → find similar images\n\nAll search is done via MongoDB's `$vectorSearch` aggregation stage.\n\n**Steps:**\n1. Embed listing cover images and store in MongoDB\n2. Create vector search index\n3. Text → image cross-modal search via `$vectorSearch`\n4. Image → image search via `$vectorSearch`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ── Setup ────────────────────────────────────────────────────────────────────\n",
    "import { MongoClient } from 'mongodb';\n",
    "\n",
    "// ← Paste your VoyageAI API key here (get one at https://dash.voyageai.com)\n",
    "const VOYAGE_API_KEY = 'pa-...';\n",
    "const MM_MODEL       = 'voyage-multimodal-3.5';\n",
    "const DIMS           = 1024;\n",
    "const INDEX_NAME     = 'multimodal_vector_index';\n",
    "\n",
    "const client = new MongoClient(process.env.MONGODB_URI!);\n",
    "await client.connect();\n",
    "const db  = client.db('voyage_lab');\n",
    "const col = db.collection<{ _id: string; [key: string]: unknown }>('listings');\n",
    "\n",
    "console.log('Connected. Model:', MM_MODEL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ── Multimodal embed helper ───────────────────────────────────────────────────\n",
    "type ContentItem =\n",
    "  | { type: 'text';      text: string }\n",
    "  | { type: 'image_url'; url: string  };\n",
    "\n",
    "async function embedMultimodal(\n",
    "  inputs: ContentItem[][],\n",
    "  inputType: 'document' | 'query' = 'document',\n",
    "): Promise<number[][]> {\n",
    "  const res = await fetch('https://api.voyageai.com/v1/multimodalembeddings', {\n",
    "    method: 'POST',\n",
    "    headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${VOYAGE_API_KEY}` },\n",
    "    body: JSON.stringify({ inputs, model: MM_MODEL, input_type: inputType }),\n",
    "  });\n",
    "  if (!res.ok) throw new Error(await res.text());\n",
    "  const json = await res.json() as { data: { embedding: number[] }[] };\n",
    "  return json.data.map(d => d.embedding);\n",
    "}\n",
    "\n",
    "console.log('Helper defined.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 — Embed listing images and store in MongoDB\n",
    "\n",
    "Each listing has a `picture_url`. We embed that URL directly — VoyageAI fetches and encodes the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ── Embed cover images for all listings ──────────────────────────────────────\n",
    "const listings = await col\n",
    "  .find({ 'images.picture_url': { $ne: '' } }, { projection: { _id: 1, name: 1, images: 1, description: 1 } })\n",
    "  .toArray();\n",
    "\n",
    "console.log(`Embedding images for ${listings.length} listings...`);\n",
    "\n",
    "const BATCH = 10;  // multimodal requests are heavier\n",
    "let done = 0;\n",
    "\n",
    "for (let i = 0; i < listings.length; i += BATCH) {\n",
    "  const batch  = listings.slice(i, i + BATCH);\n",
    "  const inputs = batch.map(l => [{ type: 'image_url' as const, url: (l.images as any).picture_url as string }]);\n",
    "  const vecs   = await embedMultimodal(inputs, 'document');\n",
    "  for (let j = 0; j < batch.length; j++) {\n",
    "    await col.updateOne({ _id: batch[j]._id }, { $set: { embedding_mm: vecs[j] } });\n",
    "  }\n",
    "  done += batch.length;\n",
    "  console.log(`Stored ${done}/${listings.length}`);\n",
    "}\n",
    "console.log('Image embeddings stored.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 — Create a Vector Search index on `embedding_mm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ── Create vector search index ────────────────────────────────────────────────\n",
    "try {\n",
    "  await col.dropSearchIndex(INDEX_NAME);\n",
    "  await new Promise(r => setTimeout(r, 2000));\n",
    "} catch { /* didn't exist */ }\n",
    "\n",
    "await col.createSearchIndex({\n",
    "  name: INDEX_NAME,\n",
    "  type: 'vectorSearch',\n",
    "  definition: {\n",
    "    fields: [\n",
    "      { type: 'vector', path: 'embedding_mm', numDimensions: DIMS, similarity: 'cosine' },\n",
    "      { type: 'filter', path: 'property_type' },\n",
    "    ],\n",
    "  },\n",
    "});\n",
    "\n",
    "console.log('Waiting for index...');\n",
    "for (let i = 0; i < 30; i++) {\n",
    "  await new Promise(r => setTimeout(r, 2000));\n",
    "  const [idx] = await col.listSearchIndexes(INDEX_NAME).toArray();\n",
    "  console.log(' status:', idx?.status);\n",
    "  if (idx?.status === 'READY') break;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 — Text → image cross-modal search\n",
    "\n",
    "The index contains image vectors. We embed a **text query** with the same multimodal model and run `$vectorSearch` — the shared space finds visually matching listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ── Text query → image results ────────────────────────────────────────────────\n",
    "const textQuery = 'bright open space with natural light and minimalist decor';\n",
    "const [qVec]    = await embedMultimodal([[{ type: 'text', text: textQuery }]], 'query');\n",
    "\n",
    "const results = await col.aggregate([\n",
    "  {\n",
    "    $vectorSearch: {\n",
    "      index:         INDEX_NAME,\n",
    "      path:          'embedding_mm',\n",
    "      queryVector:   qVec,\n",
    "      numCandidates: 50,\n",
    "      limit:         5,\n",
    "    },\n",
    "  },\n",
    "  {\n",
    "    $project: {\n",
    "      name:          1,\n",
    "      property_type: 1,\n",
    "      picture_url:   '$images.picture_url',\n",
    "      score:         { $meta: 'vectorSearchScore' },\n",
    "    },\n",
    "  },\n",
    "]).toArray();\n",
    "\n",
    "console.log(`Cross-modal results for: \"${textQuery}\"\\n`);\n",
    "console.table(results.map(r => ({ name: r.name, type: r.property_type, score: (r.score as number).toFixed(4) })));\n",
    "// OBSERVE: Results are ranked by visual similarity to the text description —\n",
    "// the model found matching images without any text in the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 — Image → image search\n",
    "\n",
    "Use a listing's own image URL as the query — find listings that look visually similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ── Image → image search ──────────────────────────────────────────────────────\n",
    "const anchor = listings[0];  // use the first listing as the query image\n",
    "const anchorUrl = (anchor.images as any).picture_url as string;\n",
    "\n",
    "const [imgQueryVec] = await embedMultimodal([[{ type: 'image_url', url: anchorUrl }]], 'query');\n",
    "\n",
    "const similar = await col.aggregate([\n",
    "  {\n",
    "    $vectorSearch: {\n",
    "      index:         INDEX_NAME,\n",
    "      path:          'embedding_mm',\n",
    "      queryVector:   imgQueryVec,\n",
    "      numCandidates: 50,\n",
    "      limit:         6,  // first result will be the query image itself\n",
    "    },\n",
    "  },\n",
    "  {\n",
    "    $project: {\n",
    "      name:  1,\n",
    "      score: { $meta: 'vectorSearchScore' },\n",
    "    },\n",
    "  },\n",
    "]).toArray();\n",
    "\n",
    "console.log(`Visually similar to: \"${anchor.name}\"\\n`);\n",
    "similar.forEach((r, i) => console.log(`  ${i === 0 ? '→ (query)' : `  ${i}.    `} [${(r.score as number).toFixed(4)}] ${r.name}`));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ── Cleanup ───────────────────────────────────────────────────────────────────\n",
    "await client.close();\n",
    "console.log('Done.');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript"
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "4.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}