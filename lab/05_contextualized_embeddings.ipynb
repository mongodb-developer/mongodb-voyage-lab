{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualized Embeddings\n",
    "\n",
    "`voyage-context-3`:\n",
    "- Takes the **full list of chunks from one document** as a single call\n",
    "- Internally captures document-level context for each chunk's vector\n",
    "- Requires **no manual prefix building** — the model does it automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { MongoClient } from 'mongodb';\n",
    "\n",
    "// ← Paste your VoyageAI API key here (get one at https://dash.voyageai.com)\n",
    "const VOYAGE_API_KEY   = 'pa-...';\n",
    "const CONTEXT_MODEL    = 'voyage-context-3';\n",
    "const STANDARD_MODEL   = 'voyage-4';\n",
    "const QUERY_MODEL      = 'voyage-4-lite';\n",
    "const DIMS             = 1024;\n",
    "const CTX_INDEX        = 'ctx_chunk_index';\n",
    "const STD_INDEX        = 'std_chunk_index';\n",
    "\n",
    "const client = new MongoClient(process.env.MONGODB_URI!);\n",
    "await client.connect();\n",
    "const db      = client.db('voyage_lab');\n",
    "const srcCol  = db.collection<{ _id: string; [key: string]: unknown }>('listings');\n",
    "const chunkCol= db.collection('chunks');\n",
    "await chunkCol.drop().catch(() => {});\n",
    "\n",
    "console.log('Connected.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 — Chunk listing descriptions\n",
    "\n",
    "We split each listing's `description` into sentence-level chunks. For `voyage-context-3`, all chunks from one listing are sent together so the model can use the full listing as context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function chunkText(text: string, maxChars = 250): string[] {\n",
    "  const sentences = text.match(/[^.!?]+[.!?]+/g) ?? [text];\n",
    "  const chunks: string[] = [];\n",
    "  let current = '';\n",
    "  for (const s of sentences) {\n",
    "    if ((current + s).length > maxChars && current) {\n",
    "      chunks.push(current.trim());\n",
    "      current = s;\n",
    "    } else {\n",
    "      current += s;\n",
    "    }\n",
    "  }\n",
    "  if (current.trim()) chunks.push(current.trim());\n",
    "  return chunks;\n",
    "}\n",
    "\n",
    "const listings = await srcCol\n",
    "  .find({}, { projection: { _id: 1, name: 1, description: 1, property_type: 1, price: 1, address: 1 } })\n",
    "  .toArray();\n",
    "\n",
    "// Build per-document chunk lists\n",
    "const docChunks = listings.map(l => ({\n",
    "  listingId:     l._id,\n",
    "  listingName:   String(l.name),\n",
    "  propertyType:  String(l.property_type),\n",
    "  price:         l.price as number,\n",
    "  market:        (l.address as any)?.market as string,\n",
    "  chunks:        chunkText(String(l.description ?? l.name)),\n",
    "}));\n",
    "\n",
    "const totalChunks = docChunks.reduce((s, d) => s + d.chunks.length, 0);\n",
    "console.log(`${listings.length} listings → ${totalChunks} chunks`);\n",
    "console.log('Example chunks from first listing:');\n",
    "docChunks[0].chunks.forEach((c, i) => console.log(`  [${i}] ${c}`));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed with `voyage-context-3` (compared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "// Standard: one flat list of texts\n",
    "async function embedStandard(texts: string[], inputType: 'document' | 'query'): Promise<number[][]> {\n",
    "  const res = await fetch('https://api.voyageai.com/v1/embeddings', {\n",
    "    method: 'POST',\n",
    "    headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${VOYAGE_API_KEY}` },\n",
    "    body: JSON.stringify({ input: texts, model: STANDARD_MODEL, input_type: inputType }),\n",
    "  });\n",
    "  if (!res.ok) throw new Error(await res.text());\n",
    "  const json = await res.json() as { data: { embedding: number[] }[] };\n",
    "  return json.data.map(d => d.embedding);\n",
    "}\n",
    "\n",
    "// Contextualized: one doc at a time — all its chunks go in together\n",
    "async function embedContextualized(chunks: string[], inputType: 'document' | 'query'): Promise<number[][]> {\n",
    "  const res = await fetch('https://api.voyageai.com/v1/contextualized_embeddings', {\n",
    "    method: 'POST',\n",
    "    headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${VOYAGE_API_KEY}` },\n",
    "    body: JSON.stringify({ inputs: [chunks], model: CONTEXT_MODEL, input_type: inputType }),\n",
    "  });\n",
    "  if (!res.ok) throw new Error(await res.text());\n",
    "\n",
    "  const json = await res.json() as { results: { embeddings: number[][] }[] };\n",
    "  return json.results[0].embeddings;\n",
    "}\n",
    "\n",
    "console.log('Helpers defined.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ── Embed all chunks and store in MongoDB ──────────────────────────────────────\n",
    "const allDocs: any[] = [];\n",
    "\n",
    "for (const doc of docChunks) {\n",
    "  if (doc.chunks.length === 0) continue;\n",
    "\n",
    "  // Contextualized: pass all chunks for this document together\n",
    "  const ctxVecs = await embedContextualized(doc.chunks, 'document');\n",
    "\n",
    "  // Standard: each chunk is independent\n",
    "  const stdVecs = await embedStandard(doc.chunks, 'document');\n",
    "\n",
    "  doc.chunks.forEach((chunk, i) => {\n",
    "    allDocs.push({\n",
    "      listingId:        doc.listingId,\n",
    "      listingName:      doc.listingName,\n",
    "      propertyType:     doc.propertyType,\n",
    "      price:            doc.price,\n",
    "      market:           doc.market,\n",
    "      chunk,\n",
    "      chunkIndex:       i,\n",
    "      embedding_ctx:    ctxVecs[i],\n",
    "      embedding_std:    stdVecs[i],\n",
    "    });\n",
    "  });\n",
    "}\n",
    "\n",
    "await chunkCol.insertMany(allDocs);\n",
    "console.log(`Stored ${allDocs.length} chunks in MongoDB.`);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create two vector search indexes and compare retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (const [name, path] of [[CTX_INDEX, 'embedding_ctx'], [STD_INDEX, 'embedding_std']]) {\n",
    "  try { await chunkCol.dropSearchIndex(name); await new Promise(r => setTimeout(r, 2000)); } catch {}\n",
    "  await chunkCol.createSearchIndex({\n",
    "    name,\n",
    "    type: 'vectorSearch',\n",
    "    definition: {\n",
    "      fields: [\n",
    "        { type: 'vector', path, numDimensions: DIMS, similarity: 'cosine' },\n",
    "        { type: 'filter', path: 'propertyType' },\n",
    "        { type: 'filter', path: 'market' },\n",
    "      ],\n",
    "    },\n",
    "  });\n",
    "  console.log(`Index '${name}' creation requested.`);\n",
    "}\n",
    "\n",
    "console.log('\\nWaiting for both indexes to be READY...');\n",
    "for (let i = 0; i < 40; i++) {\n",
    "  await new Promise(r => setTimeout(r, 3000));\n",
    "  const idxs = await chunkCol.listSearchIndexes().toArray();\n",
    "  const statuses = Object.fromEntries(idxs.map(x => [x.name, x.status]));\n",
    "  console.log(statuses);\n",
    "  if (Object.values(statuses).every(s => s === 'READY')) break;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ── Side-by-side comparison ───────────────────────────────────────────────────\n",
    "const testQueries = [\n",
    "  'garden and outdoor relaxation',\n",
    "  'remote work with fast wifi and dedicated desk',\n",
    "  'historic building with original architecture',\n",
    "];\n",
    "\n",
    "for (const q of testQueries) {\n",
    "  const [qVec] = await embedStandard([q], 'query');\n",
    "\n",
    "  const search = async (index: string, path: string) =>\n",
    "    chunkCol.aggregate([\n",
    "      { $vectorSearch: { index, path, queryVector: qVec, numCandidates: 50, limit: 3 } },\n",
    "      { $project: { listingName: 1, chunk: 1, score: { $meta: 'vectorSearchScore' } } },\n",
    "    ]).toArray();\n",
    "\n",
    "  const [ctxHits, stdHits] = await Promise.all([\n",
    "    search(CTX_INDEX, 'embedding_ctx'),\n",
    "    search(STD_INDEX, 'embedding_std'),\n",
    "  ]);\n",
    "\n",
    "  console.log(`\\nQuery: \"${q}\"`);\n",
    "  console.log('  voyage-context-3:');\n",
    "  ctxHits.forEach((h, i) => console.log(`    ${i+1}. [${(h.score as number).toFixed(4)}] ${h.listingName} — \"${String(h.chunk).substring(0, 60)}...\"`))\n",
    "  console.log('  voyage-4 (standard):');\n",
    "  stdHits.forEach((h, i) => console.log(`    ${i+1}. [${(h.score as number).toFixed(4)}] ${h.listingName} — \"${String(h.chunk).substring(0, 60)}...\"`))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ── Cleanup ───────────────────────────────────────────────────────────────────\n",
    "await chunkCol.drop();\n",
    "await client.close();\n",
    "console.log('Done.');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript"
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "4.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
